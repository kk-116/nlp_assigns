{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcUGkcGqBVkh",
        "outputId": "8e2019fd-960b-4c5b-ecb6-29387dcaf0ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/krishna/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/krishna/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package semcor to /home/krishna/nltk_data...\n",
            "[nltk_data]   Package semcor is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/krishna/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/krishna/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package omw-1.4 to /home/krishna/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(['punkt', 'wordnet', 'semcor', 'stopwords', 'averaged_perceptron_tagger'])\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import semcor\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('omw-1.4')\n",
        "import random\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from num2words import num2words\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "jDHkdaRgmIox"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "W2V = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "yDdlSB8ls8dn"
      },
      "outputs": [],
      "source": [
        "EXTRA_SW = [\n",
        "    \"''\",\n",
        "    \"'s\",\n",
        "    \"``\"\n",
        "]\n",
        "\n",
        "SW = stopwords.words(\"english\")\n",
        "SW += [p for p in punctuation]\n",
        "SW += EXTRA_SW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "me_BQR1CFNIV"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "X5FEJTwHCKL7"
      },
      "outputs": [],
      "source": [
        "def cosineSimilarity(a, b):\n",
        "    cs = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "    return cs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "iGRFnQT2q5pB"
      },
      "outputs": [],
      "source": [
        "def isNumber(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "0wXiU_kbhHNK"
      },
      "outputs": [],
      "source": [
        "def n2w(w):\n",
        "    if isNumber(w) and w.lower() != \"infinity\" and w.lower() != \"nan\":\n",
        "        w = num2words(w)\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "FNsc0CgC4qiP"
      },
      "outputs": [],
      "source": [
        "def lemmatize(w, tag):\n",
        "    if tag is None:\n",
        "        return lemmatizer.lemmatize(w)\n",
        "    else:\n",
        "        return lemmatizer.lemmatize(w, tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "def treebank2wn(ttag):\n",
        "    if ttag.startswith(\"N\"):\n",
        "        return wn.NOUN\n",
        "    # elif ttag.startswith(\"V\"):\n",
        "    #     return wn.VERB\n",
        "    # elif ttag.startswith(\"J\"):\n",
        "    #     return wn.ADJ\n",
        "    # elif ttag.startswith(\"R\"):\n",
        "    #     return wn.ADV\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "NEBmWMwVuBKU"
      },
      "outputs": [],
      "source": [
        "def clean(tokens):\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "    lemmatized = [lemmatize(w, treebank2wn(tag)) for w, tag in tagged]\n",
        "    cleaned = [n2w(w) for w in lemmatized if w.lower() not in SW]\n",
        "    return cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "n3U2-JoBmls2"
      },
      "outputs": [],
      "source": [
        "def getVec(w):\n",
        "    try:\n",
        "        v = W2V[w]\n",
        "        return v\n",
        "    except KeyError:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "nkY8QXnBS7Bv"
      },
      "outputs": [],
      "source": [
        "def syn2sense(syn):\n",
        "    s = syn.name()\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "fvRoWEzRz0oi"
      },
      "outputs": [],
      "source": [
        "# def treebank2wn(ttag):\n",
        "#     if ttag.startswith(\"J\"):\n",
        "#         return wn.ADJ\n",
        "#     elif ttag.startswith(\"V\"):\n",
        "#         return wn.VERB\n",
        "#     elif ttag.startswith(\"N\"):\n",
        "#         return wn.NOUN\n",
        "#     elif ttag.startswith(\"R\"):\n",
        "#         return wn.ADV\n",
        "#     else:\n",
        "#         return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "swX0ECwZ76up"
      },
      "outputs": [],
      "source": [
        "def sent2vec(tokens):\n",
        "\n",
        "    v = 0\n",
        "    n = 0\n",
        "\n",
        "    for w in tokens:\n",
        "\n",
        "        tkns = word_tokenize(w)\n",
        "\n",
        "        if len(tkns) > 1:\n",
        "            for t in tkns:\n",
        "                vt = getVec(t)\n",
        "                if vt is not None:\n",
        "                    n += 1\n",
        "                    v += vt\n",
        "        else:\n",
        "            vw = getVec(w)\n",
        "            if vw is not None:\n",
        "                n += 1\n",
        "                v += vw\n",
        "\n",
        "    if n == 0:\n",
        "        v = None\n",
        "    else:\n",
        "        v /= n\n",
        "\n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "U27aDOsWFbdA"
      },
      "outputs": [],
      "source": [
        "def parse(d):\n",
        "\n",
        "    tokens = []\n",
        "    senses = []\n",
        "\n",
        "    for e in d:\n",
        "\n",
        "        if isinstance(e, nltk.tree.Tree):\n",
        "\n",
        "            lemma = e.label()\n",
        "            \n",
        "            if isinstance(lemma, nltk.corpus.reader.wordnet.Lemma):\n",
        "                synset = lemma.synset()\n",
        "                sense = syn2sense(synset)\n",
        "            else:\n",
        "                sense = None\n",
        "            \n",
        "            le = len(e)\n",
        "            if le == 1:\n",
        "                w = e[0]\n",
        "                if isinstance(w, nltk.tree.Tree) or isinstance(w, list):\n",
        "                    lw = len(w)\n",
        "                    w = \" \".join([w[i] for i in range(lw)])\n",
        "            else:\n",
        "                w = \" \".join([e[i] for i in range(le)])\n",
        "\n",
        "        elif isinstance(e, list):\n",
        "            w = e[0]\n",
        "            sense = None\n",
        "\n",
        "        else:\n",
        "            invtype = type(e)\n",
        "            raise TypeError(f\"Invalid type: {invtype}\")\n",
        "\n",
        "        if w:\n",
        "            tokens.append(w)\n",
        "            senses.append(sense)\n",
        "\n",
        "    return tokens, senses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "WoJRkwmc_laW"
      },
      "outputs": [],
      "source": [
        "def getCandidates(w, tag):\n",
        "\n",
        "    w = w.replace(\".\", \"\")\n",
        "    w = w.replace(\"-\", \"\")\n",
        "\n",
        "    tkns = word_tokenize(w)\n",
        "    if len(tkns) > 1:\n",
        "        tagged = nltk.pos_tag(tkns)\n",
        "        tags = [treebank2wn(p[1]) for p in tagged]\n",
        "        ltkns = [lemmatize(w, t) for w, t in zip(tkns, tags)]\n",
        "        w = \"_\".join(ltkns)\n",
        "\n",
        "    syns = wn.synsets(w, tag)\n",
        "\n",
        "    if len(syns) == 0:\n",
        "        w = \"_\".join(tkns)\n",
        "        syns = wn.synsets(w, tag)\n",
        "\n",
        "    sense_vectors = []\n",
        "    sense_labels = []\n",
        "\n",
        "    for syn in syns:\n",
        "\n",
        "        label = syn2sense(syn)\n",
        "\n",
        "        defn = syn.definition()\n",
        "\n",
        "        defn = defn.replace(\"_\", \" \")\n",
        "        defn = defn.replace(\"-\", \" \")\n",
        "\n",
        "        tkns = word_tokenize(defn)\n",
        "        if len(tkns) == 0:\n",
        "            raise ValueError(f\"0 tokens found: {defn}\")\n",
        "\n",
        "        clnd = clean(tkns)\n",
        "        if len(clnd) < 2:\n",
        "            clnd = tkns\n",
        "\n",
        "        sv = sent2vec(clnd)\n",
        "\n",
        "        if sv is None:\n",
        "            print(f\"Empty sense vector. Word: {w}, Definition: {defn}, Cleaned: {clnd}. Using a random vector as sense.\")\n",
        "            sv = np.random.rand(300,)\n",
        "        \n",
        "        sense_vectors.append(sv)\n",
        "        sense_labels.append(label)\n",
        "\n",
        "    return sense_vectors, sense_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "_yqFveUQDYQD"
      },
      "outputs": [],
      "source": [
        "data = semcor.tagged_sents(tag = \"sem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUegBwQjrUlb",
        "outputId": "61d7a56c-294e-465d-b991-217ef18ff0a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 sentences processed\n",
            "Accuracy: 41.7108\n",
            "\n",
            "400 sentences processed\n",
            "Accuracy: 39.7835\n",
            "\n",
            "600 sentences processed\n",
            "Accuracy: 38.9822\n",
            "\n",
            "800 sentences processed\n",
            "Accuracy: 38.1238\n",
            "\n",
            "1000 sentences processed\n",
            "Accuracy: 38.2491\n",
            "\n",
            "1200 sentences processed\n",
            "Accuracy: 37.9501\n",
            "\n",
            "1400 sentences processed\n",
            "Accuracy: 37.9943\n",
            "\n",
            "1600 sentences processed\n",
            "Accuracy: 38.3436\n",
            "\n",
            "1800 sentences processed\n",
            "Accuracy: 38.2648\n",
            "\n",
            "2000 sentences processed\n",
            "Accuracy: 38.1458\n",
            "\n",
            "2200 sentences processed\n",
            "Accuracy: 38.1071\n",
            "\n",
            "Empty context vector. Word: Cancer, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Cancer', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: By no means, Cleaned: ['.'], Tokens: ['By no means', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: For instance, Cleaned: [':'], Tokens: ['For instance', ':']. Using a random vector as context.\n",
            "Empty context vector. Word: Death, Cleaned: ['!'], Tokens: ['Death', '!']. Using a random vector as context.\n",
            "2400 sentences processed\n",
            "Accuracy: 38.3493\n",
            "\n",
            "2600 sentences processed\n",
            "Accuracy: 38.4535\n",
            "\n",
            "2800 sentences processed\n",
            "Accuracy: 38.6092\n",
            "\n",
            "3000 sentences processed\n",
            "Accuracy: 39.0109\n",
            "\n",
            "3200 sentences processed\n",
            "Accuracy: 39.3462\n",
            "\n",
            "3400 sentences processed\n",
            "Accuracy: 39.8211\n",
            "\n",
            "3600 sentences processed\n",
            "Accuracy: 40.2267\n",
            "\n",
            "3800 sentences processed\n",
            "Accuracy: 40.5579\n",
            "\n",
            "4000 sentences processed\n",
            "Accuracy: 40.8442\n",
            "\n",
            "4200 sentences processed\n",
            "Accuracy: 41.3155\n",
            "\n",
            "4400 sentences processed\n",
            "Accuracy: 41.5798\n",
            "\n",
            "4600 sentences processed\n",
            "Accuracy: 41.4287\n",
            "\n",
            "4800 sentences processed\n",
            "Accuracy: 41.3698\n",
            "\n",
            "5000 sentences processed\n",
            "Accuracy: 41.0805\n",
            "\n",
            "5200 sentences processed\n",
            "Accuracy: 40.8832\n",
            "\n",
            "Empty context vector. Word: Therefore, Cleaned: [','], Tokens: ['Therefore', ',']. Using a random vector as context.\n",
            "5400 sentences processed\n",
            "Accuracy: 40.6396\n",
            "\n",
            "5600 sentences processed\n",
            "Accuracy: 40.8389\n",
            "\n",
            "5800 sentences processed\n",
            "Accuracy: 40.7314\n",
            "\n",
            "Empty context vector. Word: Mines, Cleaned: ['.'], Tokens: ['Mines', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Mines, Cleaned: ['.'], Tokens: ['Mines', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Mines, Cleaned: ['.'], Tokens: ['Mines', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Mines, Cleaned: ['.'], Tokens: ['Mines', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Wait, Cleaned: ['``', '!'], Tokens: ['``', 'Wait', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: All right, Cleaned: ['``', '.'], Tokens: ['``', 'All right', '.']. Using a random vector as context.\n",
            "6000 sentences processed\n",
            "Accuracy: 40.5426\n",
            "\n",
            "6200 sentences processed\n",
            "Accuracy: 40.4134\n",
            "\n",
            "Empty context vector. Word: Stevie, Cleaned: ['``', '!'], Tokens: ['``', 'Stevie', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Stevie, Cleaned: [\"''\", '!'], Tokens: ['Stevie', \"''\", '!']. Using a random vector as context.\n",
            "6400 sentences processed\n",
            "Accuracy: 40.3091\n",
            "\n",
            "Empty sense vector. Word: ruffled, Definition: discompose, Cleaned: ['discompose']. Using a random vector as sense.\n",
            "Empty context vector. Word: Months, Cleaned: ['.'], Tokens: ['Months', '.']. Using a random vector as context.\n",
            "6600 sentences processed\n",
            "Accuracy: 40.2381\n",
            "\n",
            "Empty context vector. Word: Brandon, Cleaned: ['.'], Tokens: ['Brandon', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Johnson, Cleaned: ['.'], Tokens: ['Johnson', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Johnson, Cleaned: ['Sleepy-eyed', 'soft-spoken'], Tokens: ['Sleepy-eyed', ',', 'soft-spoken', 'Johnson', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Knows the score, Cleaned: ['.'], Tokens: ['Knows the score', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Top dog, Cleaned: ['.'], Tokens: ['Top dog', '.']. Using a random vector as context.\n",
            "6800 sentences processed\n",
            "Accuracy: 40.1503\n",
            "\n",
            "7000 sentences processed\n",
            "Accuracy: 39.9461\n",
            "\n",
            "Empty context vector. Word: Eli Corault, Cleaned: ['!'], Tokens: ['Eli Corault', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: John, Cleaned: ['``', '?'], Tokens: ['``', 'John', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Plot, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Plot', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Heretic, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Heretic', \"''\", '!']. Using a random vector as context.\n",
            "7200 sentences processed\n",
            "Accuracy: 39.8384\n",
            "\n",
            "7400 sentences processed\n",
            "Accuracy: 39.7909\n",
            "\n",
            "Empty context vector. Word: Locked, Cleaned: ['.'], Tokens: ['Locked', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Workmen, Cleaned: ['``', '.'], Tokens: ['``', 'Workmen', '.']. Using a random vector as context.\n",
            "7600 sentences processed\n",
            "Accuracy: 39.7148\n",
            "\n",
            "Empty context vector. Word: Tomorrow, Cleaned: ['``', '.'], Tokens: ['``', 'Tomorrow', '.']. Using a random vector as context.\n",
            "7800 sentences processed\n",
            "Accuracy: 39.5478\n",
            "\n",
            "Empty context vector. Word: Warsaw, Cleaned: ['!'], Tokens: ['Warsaw', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Warsaw, Cleaned: ['!'], Tokens: ['Warsaw', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Warsaw, Cleaned: ['!'], Tokens: ['Warsaw', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Miss Rak, Cleaned: ['``', '.'], Tokens: ['``', 'Miss Rak', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Deportees, Cleaned: ['.'], Tokens: ['Deportees', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Jews, Cleaned: ['.'], Tokens: ['Jews', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Captain Androfski, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Captain Androfski', \"''\", '!']. Using a random vector as context.\n",
            "8000 sentences processed\n",
            "Accuracy: 39.5091\n",
            "\n",
            "Empty context vector. Word: Precious, Cleaned: ['``', '.'], Tokens: ['``', 'Precious', '.']. Using a random vector as context.\n",
            "8200 sentences processed\n",
            "Accuracy: 39.3872\n",
            "\n",
            "8400 sentences processed\n",
            "Accuracy: 39.2828\n",
            "\n",
            "Empty context vector. Word: Byron, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Byron', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Beckworth, Cleaned: ['-', '.'], Tokens: ['-', 'Beckworth', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Sir, Cleaned: ['-', '?'], Tokens: ['-', 'Sir', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Exactly, Cleaned: ['!'], Tokens: ['Exactly', '!']. Using a random vector as context.\n",
            "8600 sentences processed\n",
            "Accuracy: 39.2306\n",
            "\n",
            "Empty context vector. Word: Henry, Cleaned: ['-', '?'], Tokens: ['-', 'Henry', '?']. Using a random vector as context.\n",
            "8800 sentences processed\n",
            "Accuracy: 39.1415\n",
            "\n",
            "Empty context vector. Word: Abel, Cleaned: [\"''\", '?'], Tokens: ['Abel', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Pedersen, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Pedersen', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Pedersen, Cleaned: ['.'], Tokens: ['Pedersen', '.']. Using a random vector as context.\n",
            "9000 sentences processed\n",
            "Accuracy: 39.0396\n",
            "\n",
            "Empty context vector. Word: Jorge, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Jorge', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Nothing, Cleaned: ['.'], Tokens: ['Nothing', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: No, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'No', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: All right, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'All right', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Shut up, Cleaned: ['``', '.'], Tokens: ['``', 'Shut up', '.']. Using a random vector as context.\n",
            "9200 sentences processed\n",
            "Accuracy: 38.9391\n",
            "\n",
            "Empty context vector. Word: Cousin Ada, Cleaned: ['``', '!'], Tokens: ['``', 'Cousin Ada', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Cousin John, Cleaned: [\"''\", '!'], Tokens: ['Cousin John', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Cousin Lura, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Cousin Lura', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Cousin Howard, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Cousin Howard', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Howard, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Howard', \"''\", '.']. Using a random vector as context.\n",
            "Empty sense vector. Word: ruffled, Definition: discompose, Cleaned: ['discompose']. Using a random vector as sense.\n",
            "Empty context vector. Word: All right, Cleaned: ['``', '.'], Tokens: ['``', 'All right', '.']. Using a random vector as context.\n",
            "9400 sentences processed\n",
            "Accuracy: 38.7959\n",
            "\n",
            "Empty context vector. Word: Leona, Cleaned: [\"''\", '!'], Tokens: ['Leona', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Winston, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Winston', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Picture, Cleaned: ['``', '!'], Tokens: ['``', 'Picture', '!']. Using a random vector as context.\n",
            "9600 sentences processed\n",
            "Accuracy: 38.6988\n",
            "\n",
            "Empty context vector. Word: Felix, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Felix', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Felix Grubb, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Felix Grubb', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Felix Grubb, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Felix Grubb', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: No, Cleaned: ['``', '.'], Tokens: ['``', 'No', '.']. Using a random vector as context.\n",
            "9800 sentences processed\n",
            "Accuracy: 38.6507\n",
            "\n",
            "Empty context vector. Word: Reporters, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Reporters', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: No, Cleaned: ['``', '.'], Tokens: ['``', 'No', '.']. Using a random vector as context.\n",
            "10000 sentences processed\n",
            "Accuracy: 38.5893\n",
            "\n",
            "Empty context vector. Word: Hi, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Hi', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Asleep, Cleaned: ['``', '.'], Tokens: ['``', 'Asleep', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Fine, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Fine', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Mike, Cleaned: ['``', '?'], Tokens: ['``', 'Mike', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Yes, Cleaned: ['``', '.'], Tokens: ['``', 'Yes', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Yes, Cleaned: ['``', '.'], Tokens: ['``', 'Yes', '.']. Using a random vector as context.\n",
            "10200 sentences processed\n",
            "Accuracy: 38.5228\n",
            "\n",
            "Empty context vector. Word: Perhaps, Cleaned: ['.'], Tokens: ['Perhaps', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Pornsen, Cleaned: ['.'], Tokens: ['Pornsen', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Jake Carwood, Cleaned: ['``', '.'], Tokens: ['``', 'Jake Carwood', '.']. Using a random vector as context.\n",
            "10400 sentences processed\n",
            "Accuracy: 38.4917\n",
            "\n",
            "Empty context vector. Word: Judith Pierce, Cleaned: ['.'], Tokens: ['Judith Pierce', '.']. Using a random vector as context.\n",
            "10600 sentences processed\n",
            "Accuracy: 38.4332\n",
            "\n",
            "Empty context vector. Word: Good, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Good', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Samples, Cleaned: [':'], Tokens: ['Samples', ':']. Using a random vector as context.\n",
            "10800 sentences processed\n",
            "Accuracy: 38.3675\n",
            "\n",
            "Empty context vector. Word: said, Cleaned: ['Furiouser', 'furiouser'], Tokens: ['``', 'Furiouser', 'and', 'furiouser', \"''\", ',', 'I', 'said', '.']. Using a random vector as context.\n",
            "11000 sentences processed\n",
            "Accuracy: 38.2927\n",
            "\n",
            "Empty context vector. Word: S. J. Perelman, Cleaned: ['.'], Tokens: ['S. J. Perelman', '.']. Using a random vector as context.\n",
            "11200 sentences processed\n",
            "Accuracy: 38.3469\n",
            "\n",
            "Empty context vector. Word: Note, Cleaned: ['(', ':'], Tokens: ['(', 'Note', ':']. Using a random vector as context.\n",
            "11400 sentences processed\n",
            "Accuracy: 38.4519\n",
            "\n",
            "11600 sentences processed\n",
            "Accuracy: 38.5452\n",
            "\n",
            "11800 sentences processed\n",
            "Accuracy: 38.5859\n",
            "\n",
            "12000 sentences processed\n",
            "Accuracy: 38.5814\n",
            "\n",
            "12200 sentences processed\n",
            "Accuracy: 38.6341\n",
            "\n",
            "12400 sentences processed\n",
            "Accuracy: 38.6408\n",
            "\n",
            "12600 sentences processed\n",
            "Accuracy: 38.6343\n",
            "\n",
            "12800 sentences processed\n",
            "Accuracy: 38.6972\n",
            "\n",
            "13000 sentences processed\n",
            "Accuracy: 38.6452\n",
            "\n",
            "13200 sentences processed\n",
            "Accuracy: 38.6475\n",
            "\n",
            "13400 sentences processed\n",
            "Accuracy: 38.6864\n",
            "\n",
            "Empty context vector. Word: No more, Cleaned: ['.'], Tokens: ['No more', '.']. Using a random vector as context.\n",
            "13600 sentences processed\n",
            "Accuracy: 38.6563\n",
            "\n",
            "13800 sentences processed\n",
            "Accuracy: 38.6173\n",
            "\n",
            "14000 sentences processed\n",
            "Accuracy: 38.6188\n",
            "\n",
            "14200 sentences processed\n",
            "Accuracy: 38.6166\n",
            "\n",
            "14400 sentences processed\n",
            "Accuracy: 38.6532\n",
            "\n",
            "14600 sentences processed\n",
            "Accuracy: 38.6024\n",
            "\n",
            "14800 sentences processed\n",
            "Accuracy: 38.6483\n",
            "\n",
            "15000 sentences processed\n",
            "Accuracy: 38.7266\n",
            "\n",
            "Empty context vector. Word: Ventilation, Cleaned: ['.'], Tokens: ['Ventilation', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Lighting, Cleaned: ['.'], Tokens: ['Lighting', '.']. Using a random vector as context.\n",
            "15200 sentences processed\n",
            "Accuracy: 38.7766\n",
            "\n",
            "15400 sentences processed\n",
            "Accuracy: 38.8674\n",
            "\n",
            "15600 sentences processed\n",
            "Accuracy: 38.9115\n",
            "\n",
            "15800 sentences processed\n",
            "Accuracy: 38.9452\n",
            "\n",
            "16000 sentences processed\n",
            "Accuracy: 38.9696\n",
            "\n",
            "16200 sentences processed\n",
            "Accuracy: 38.9691\n",
            "\n",
            "16400 sentences processed\n",
            "Accuracy: 38.9759\n",
            "\n",
            "Empty context vector. Word: Sure, Cleaned: ['.'], Tokens: ['Sure', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Sure, Cleaned: ['.'], Tokens: ['Sure', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Katharine, Cleaned: ['.'], Tokens: ['Katharine', '.']. Using a random vector as context.\n",
            "16600 sentences processed\n",
            "Accuracy: 38.9309\n",
            "\n",
            "Empty context vector. Word: Coffee, Cleaned: ['.'], Tokens: ['Coffee', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Maude, Cleaned: ['?'], Tokens: ['Maude', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Maude, Cleaned: ['.'], Tokens: ['Maude', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Glendora, Cleaned: [\"''\", '-'], Tokens: ['Glendora', \"''\", '-']. Using a random vector as context.\n",
            "Empty context vector. Word: secretary, Cleaned: ['``', 'Gilborn', \"'s\", '?'], Tokens: ['``', 'Gilborn', \"'s\", 'secretary', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Right, Cleaned: ['``', '.'], Tokens: ['``', 'Right', '.']. Using a random vector as context.\n",
            "16800 sentences processed\n",
            "Accuracy: 38.8761\n",
            "\n",
            "Empty context vector. Word: Dad, Cleaned: ['``', '.'], Tokens: ['``', 'Dad', '.']. Using a random vector as context.\n",
            "17000 sentences processed\n",
            "Accuracy: 38.8167\n",
            "\n",
            "Empty context vector. Word: Mae, Cleaned: ['``', \"''\", '-'], Tokens: ['``', 'Mae', \"''\", '-']. Using a random vector as context.\n",
            "17200 sentences processed\n",
            "Accuracy: 38.7928\n",
            "\n",
            "Empty context vector. Word: Motive, Cleaned: ['.'], Tokens: ['Motive', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Right, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Right', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Mullins, Cleaned: ['?'], Tokens: ['Mullins', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Motive, Cleaned: ['?'], Tokens: ['Motive', '?']. Using a random vector as context.\n",
            "17400 sentences processed\n",
            "Accuracy: 38.7748\n",
            "\n",
            "Empty context vector. Word: bequest, Cleaned: ['Ten-thousand-dollar', '.'], Tokens: ['Ten-thousand-dollar', 'bequest', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Impossible, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Impossible', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: office, Cleaned: ['Mahzeer', \"'s\", \"''\", '.'], Tokens: ['Mahzeer', \"'s\", 'office', \"''\", '.']. Using a random vector as context.\n",
            "17600 sentences processed\n",
            "Accuracy: 38.7579\n",
            "\n",
            "Empty context vector. Word: Sir, Cleaned: ['``', '.'], Tokens: ['``', 'Sir', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Jack, Cleaned: [':'], Tokens: ['Jack', ':']. Using a random vector as context.\n",
            "Empty context vector. Word: Casey, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Casey', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Tony Calenda, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Tony Calenda', \"''\", '.']. Using a random vector as context.\n",
            "17800 sentences processed\n",
            "Accuracy: 38.7330\n",
            "\n",
            "Empty context vector. Word: Casey, Cleaned: ['``', '?'], Tokens: ['``', 'Casey', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Tom, Cleaned: ['``', '!'], Tokens: ['``', 'Tom', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Donna, Cleaned: ['!'], Tokens: ['Donna', '!']. Using a random vector as context.\n",
            "18000 sentences processed\n",
            "Accuracy: 38.7031\n",
            "\n",
            "Empty context vector. Word: Five, Cleaned: ['?'], Tokens: ['Five', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Ten, Cleaned: ['?'], Tokens: ['Ten', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Key, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Key', \"''\", '?']. Using a random vector as context.\n",
            "18200 sentences processed\n",
            "Accuracy: 38.6672\n",
            "\n",
            "Empty context vector. Word: Sportin, Cleaned: ['``', \"''\", \"'\", '!'], Tokens: ['``', 'Sportin', \"''\", \"'\", '!']. Using a random vector as context.\n",
            "18400 sentences processed\n",
            "Accuracy: 38.6208\n",
            "\n",
            "Empty context vector. Word: Arbuckle, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Arbuckle', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: No, Cleaned: ['``', '.'], Tokens: ['``', 'No', '.']. Using a random vector as context.\n",
            "18600 sentences processed\n",
            "Accuracy: 38.5632\n",
            "\n",
            "18800 sentences processed\n",
            "Accuracy: 38.5031\n",
            "\n",
            "Empty context vector. Word: Now, Cleaned: ['!'], Tokens: ['Now', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Get in, Cleaned: [\"''\", '.'], Tokens: ['Get in', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: S-s-sahjunt, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'S-s-sahjunt', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Sure, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Sure', \"''\", '.']. Using a random vector as context.\n",
            "19000 sentences processed\n",
            "Accuracy: 38.4607\n",
            "\n",
            "Empty context vector. Word: Splendid, Cleaned: ['``', '.'], Tokens: ['``', 'Splendid', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Murder, Cleaned: ['``', '?'], Tokens: ['``', 'Murder', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Itch, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Itch', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Goodbye, Cleaned: ['``', '.'], Tokens: ['``', 'Goodbye', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Softly, Cleaned: ['.'], Tokens: ['Softly', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Warmly, Cleaned: ['.'], Tokens: ['Warmly', '.']. Using a random vector as context.\n",
            "19200 sentences processed\n",
            "Accuracy: 38.4215\n",
            "\n",
            "Empty context vector. Word: Very well, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Very well', \"''\", '.']. Using a random vector as context.\n",
            "19400 sentences processed\n",
            "Accuracy: 38.3892\n",
            "\n",
            "Empty context vector. Word: Osric Pendleton, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Osric Pendleton', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: laughed, Cleaned: ['Askington', '.'], Tokens: ['Askington', 'laughed', '.']. Using a random vector as context.\n",
            "19600 sentences processed\n",
            "Accuracy: 38.3466\n",
            "\n",
            "Empty context vector. Word: Nothing, Cleaned: ['``', '.'], Tokens: ['``', 'Nothing', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Third, Cleaned: ['``', '!'], Tokens: ['``', 'Third', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Third base, Cleaned: [\"''\", '!'], Tokens: ['Third base', \"''\", '!']. Using a random vector as context.\n",
            "19800 sentences processed\n",
            "Accuracy: 38.2944\n",
            "\n",
            "20000 sentences processed\n",
            "Accuracy: 38.2573\n",
            "\n",
            "20200 sentences processed\n",
            "Accuracy: 38.2151\n",
            "\n",
            "20400 sentences processed\n",
            "Accuracy: 38.1541\n",
            "\n",
            "20600 sentences processed\n",
            "Accuracy: 38.1015\n",
            "\n",
            "20800 sentences processed\n",
            "Accuracy: 38.0491\n",
            "\n",
            "21000 sentences processed\n",
            "Accuracy: 38.0097\n",
            "\n",
            "21200 sentences processed\n",
            "Accuracy: 37.9650\n",
            "\n",
            "21400 sentences processed\n",
            "Accuracy: 37.9326\n",
            "\n",
            "21600 sentences processed\n",
            "Accuracy: 37.8781\n",
            "\n",
            "21800 sentences processed\n",
            "Accuracy: 37.8271\n",
            "\n",
            "22000 sentences processed\n",
            "Accuracy: 37.7884\n",
            "\n",
            "22200 sentences processed\n",
            "Accuracy: 37.7510\n",
            "\n",
            "22400 sentences processed\n",
            "Accuracy: 37.7062\n",
            "\n",
            "22600 sentences processed\n",
            "Accuracy: 37.6612\n",
            "\n",
            "22800 sentences processed\n",
            "Accuracy: 37.6064\n",
            "\n",
            "23000 sentences processed\n",
            "Accuracy: 37.5454\n",
            "\n",
            "23200 sentences processed\n",
            "Accuracy: 37.4976\n",
            "\n",
            "23400 sentences processed\n",
            "Accuracy: 37.4513\n",
            "\n",
            "23600 sentences processed\n",
            "Accuracy: 37.4104\n",
            "\n",
            "23800 sentences processed\n",
            "Accuracy: 37.3606\n",
            "\n",
            "24000 sentences processed\n",
            "Accuracy: 37.3091\n",
            "\n",
            "24200 sentences processed\n",
            "Accuracy: 37.2678\n",
            "\n",
            "24400 sentences processed\n",
            "Accuracy: 37.2213\n",
            "\n",
            "24600 sentences processed\n",
            "Accuracy: 37.1832\n",
            "\n",
            "24800 sentences processed\n",
            "Accuracy: 37.1333\n",
            "\n",
            "25000 sentences processed\n",
            "Accuracy: 37.0872\n",
            "\n",
            "25200 sentences processed\n",
            "Accuracy: 37.0395\n",
            "\n",
            "25400 sentences processed\n",
            "Accuracy: 37.0036\n",
            "\n",
            "Empty context vector. Word: understood, Cleaned: ['Leninism-Marxism', 'Exegete'], Tokens: ['Leninism-Marxism', ',', 'a', 'understood', 'by', 'Exegete', '.']. Using a random vector as context.\n",
            "25600 sentences processed\n",
            "Accuracy: 36.9551\n",
            "\n",
            "25800 sentences processed\n",
            "Accuracy: 36.9111\n",
            "\n",
            "26000 sentences processed\n",
            "Accuracy: 36.8629\n",
            "\n",
            "26200 sentences processed\n",
            "Accuracy: 36.8181\n",
            "\n",
            "26400 sentences processed\n",
            "Accuracy: 36.7719\n",
            "\n",
            "26600 sentences processed\n",
            "Accuracy: 36.7210\n",
            "\n",
            "26800 sentences processed\n",
            "Accuracy: 36.6841\n",
            "\n",
            "27000 sentences processed\n",
            "Accuracy: 36.6387\n",
            "\n",
            "27200 sentences processed\n",
            "Accuracy: 36.5919\n",
            "\n",
            "27400 sentences processed\n",
            "Accuracy: 36.5361\n",
            "\n",
            "27600 sentences processed\n",
            "Accuracy: 36.4792\n",
            "\n",
            "27800 sentences processed\n",
            "Accuracy: 36.4302\n",
            "\n",
            "28000 sentences processed\n",
            "Accuracy: 36.3676\n",
            "\n",
            "28200 sentences processed\n",
            "Accuracy: 36.3351\n",
            "\n",
            "28400 sentences processed\n",
            "Accuracy: 36.2985\n",
            "\n",
            "28600 sentences processed\n",
            "Accuracy: 36.2510\n",
            "\n",
            "28800 sentences processed\n",
            "Accuracy: 36.2022\n",
            "\n",
            "29000 sentences processed\n",
            "Accuracy: 36.1744\n",
            "\n",
            "29200 sentences processed\n",
            "Accuracy: 36.1319\n",
            "\n",
            "29400 sentences processed\n",
            "Accuracy: 36.0938\n",
            "\n",
            "Empty context vector. Word: Simmer, Cleaned: ['15', '.'], Tokens: ['Simmer', '15', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Serves, Cleaned: ['12', '.'], Tokens: ['Serves', '12', '.']. Using a random vector as context.\n",
            "29600 sentences processed\n",
            "Accuracy: 36.0598\n",
            "\n",
            "29800 sentences processed\n",
            "Accuracy: 36.0305\n",
            "\n",
            "30000 sentences processed\n",
            "Accuracy: 35.9904\n",
            "\n",
            "30200 sentences processed\n",
            "Accuracy: 35.9553\n",
            "\n",
            "Empty context vector. Word: Stop, Cleaned: ['``', '!'], Tokens: ['``', 'Stop', '!']. Using a random vector as context.\n",
            "30400 sentences processed\n",
            "Accuracy: 35.9224\n",
            "\n",
            "30600 sentences processed\n",
            "Accuracy: 35.8848\n",
            "\n",
            "30800 sentences processed\n",
            "Accuracy: 35.8510\n",
            "\n",
            "31000 sentences processed\n",
            "Accuracy: 35.8134\n",
            "\n",
            "31200 sentences processed\n",
            "Accuracy: 35.7665\n",
            "\n",
            "Empty sense vector. Word: ruffle, Definition: discompose, Cleaned: ['discompose']. Using a random vector as sense.\n",
            "31400 sentences processed\n",
            "Accuracy: 35.7396\n",
            "\n",
            "31600 sentences processed\n",
            "Accuracy: 35.7032\n",
            "\n",
            "31800 sentences processed\n",
            "Accuracy: 35.6658\n",
            "\n",
            "32000 sentences processed\n",
            "Accuracy: 35.6308\n",
            "\n",
            "32200 sentences processed\n",
            "Accuracy: 35.5903\n",
            "\n",
            "32400 sentences processed\n",
            "Accuracy: 35.5573\n",
            "\n",
            "32600 sentences processed\n",
            "Accuracy: 35.5183\n",
            "\n",
            "32800 sentences processed\n",
            "Accuracy: 35.4888\n",
            "\n",
            "33000 sentences processed\n",
            "Accuracy: 35.4597\n",
            "\n",
            "33200 sentences processed\n",
            "Accuracy: 35.4310\n",
            "\n",
            "33400 sentences processed\n",
            "Accuracy: 35.3864\n",
            "\n",
            "33600 sentences processed\n",
            "Accuracy: 35.3352\n",
            "\n",
            "33800 sentences processed\n",
            "Accuracy: 35.3106\n",
            "\n",
            "34000 sentences processed\n",
            "Accuracy: 35.2813\n",
            "\n",
            "34200 sentences processed\n",
            "Accuracy: 35.2515\n",
            "\n",
            "34400 sentences processed\n",
            "Accuracy: 35.2134\n",
            "\n",
            "Empty context vector. Word: Receiving, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Receiving', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: asked, Cleaned: ['Ekstrohm', '.'], Tokens: ['Ekstrohm', 'asked', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Take it easy, Cleaned: [\"''\", '.'], Tokens: ['Take it easy', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: suggested, Cleaned: ['Ekstrohm', '.'], Tokens: ['Ekstrohm', 'suggested', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: stood up, Cleaned: ['Ekstrohm', '.'], Tokens: ['Ekstrohm', 'stood up', '.']. Using a random vector as context.\n",
            "34600 sentences processed\n",
            "Accuracy: 35.1904\n",
            "\n",
            "Empty context vector. Word: demanded, Cleaned: ['Ekstrohm', '.'], Tokens: ['Ekstrohm', 'demanded', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: scowled, Cleaned: ['Ekstrohm', '.'], Tokens: ['Ekstrohm', 'scowled', '.']. Using a random vector as context.\n",
            "34800 sentences processed\n",
            "Accuracy: 35.1648\n",
            "\n",
            "Empty context vector. Word: Get up, Cleaned: ['``', '.'], Tokens: ['``', 'Get up', '.']. Using a random vector as context.\n",
            "35000 sentences processed\n",
            "Accuracy: 35.1259\n",
            "\n",
            "35200 sentences processed\n",
            "Accuracy: 35.1002\n",
            "\n",
            "35400 sentences processed\n",
            "Accuracy: 35.0776\n",
            "\n",
            "Empty context vector. Word: Hurry, Cleaned: ['``', '!'], Tokens: ['``', 'Hurry', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Hurry, Cleaned: [\"''\", '!'], Tokens: ['Hurry', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Hustle, Cleaned: [\"''\", '!'], Tokens: ['Hustle', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Fort up, Cleaned: ['!'], Tokens: ['Fort up', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Lead up, Cleaned: ['``', '!'], Tokens: ['``', 'Lead up', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Lead up, Cleaned: ['!'], Tokens: ['Lead up', '!']. Using a random vector as context.\n",
            "35600 sentences processed\n",
            "Accuracy: 35.0536\n",
            "\n",
            "35800 sentences processed\n",
            "Accuracy: 35.0240\n",
            "\n",
            "36000 sentences processed\n",
            "Accuracy: 34.9933\n",
            "\n",
            "36200 sentences processed\n",
            "Accuracy: 34.9568\n",
            "\n",
            "36400 sentences processed\n",
            "Accuracy: 34.9120\n",
            "\n",
            "Empty context vector. Word: Take off, Cleaned: ['``', ',', 'fly-boy', \"''\", '!'], Tokens: ['``', 'Take off', ',', 'fly-boy', \"''\", '!']. Using a random vector as context.\n",
            "36600 sentences processed\n",
            "Accuracy: 34.8724\n",
            "\n",
            "36800 sentences processed\n",
            "Accuracy: 34.8440\n",
            "\n",
            "37000 sentences processed\n",
            "Accuracy: 34.8119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_total = 0\n",
        "n_correct = 0\n",
        "n_samples = 0\n",
        "\n",
        "true = []\n",
        "pred = []\n",
        "\n",
        "for d in data:\n",
        "\n",
        "    try:\n",
        "\n",
        "        tokens, senses = parse(d)\n",
        "        n_tokens = len(tokens)\n",
        "\n",
        "        tagged = nltk.pos_tag(tokens)\n",
        "        tags = [treebank2wn(p[1]) for p in tagged]\n",
        "        tokens = [lemmatize(w, tag) for w, tag in zip(tokens, tags)]\n",
        "\n",
        "        for i in range(n_tokens):\n",
        "\n",
        "            w = tokens[i]\n",
        "            tag = tags[i]\n",
        "            s_true = senses[i]\n",
        "\n",
        "            if not isinstance(w, str):\n",
        "                raise TypeError(f\"Invalid type: {type(w)} : {w} : {tokens}\")\n",
        "\n",
        "            if s_true is None:\n",
        "                continue\n",
        "\n",
        "            context = tokens.copy()\n",
        "            del context[i]\n",
        "\n",
        "            cleaned = clean(context)\n",
        "            if len(cleaned) < 2:\n",
        "                cleaned = context\n",
        "                \n",
        "            cv = sent2vec(cleaned)\n",
        "\n",
        "            if cv is None:\n",
        "                print(f\"Empty context vector. Word: {w}, Cleaned: {cleaned}, Tokens: {tokens}. Using a random vector as context.\")\n",
        "                cv = np.random.rand(300,)\n",
        "\n",
        "            sense_vectors, sense_labels = getCandidates(w, tag)\n",
        "            n_candidates = len(sense_labels)\n",
        "\n",
        "            s_pred = None\n",
        "            if n_candidates == 0:\n",
        "                sense_vectors, sense_labels = getCandidates(w, None)\n",
        "                n_candidates = len(sense_labels)\n",
        "                if n_candidates == 0:\n",
        "                    s_pred = random.choice([\"group.n.01\", \"person.n.01\", \"location.n.01\"])\n",
        "            \n",
        "            best = -1 \n",
        "            for j in range(n_candidates):\n",
        "                sv = sense_vectors[j]\n",
        "                cs = cosineSimilarity(cv, sv)\n",
        "                if cs > best:\n",
        "                    best = cs\n",
        "                    s_pred = sense_labels[j]\n",
        "\n",
        "            if s_true == s_pred:\n",
        "                n_correct += 1\n",
        "            n_total += 1\n",
        "\n",
        "            true.append(s_true)\n",
        "            pred.append(s_pred)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error at: {n_samples}\")\n",
        "        print(str(e))\n",
        "        raise ValueError(\"Error\")\n",
        "\n",
        "    n_samples += 1\n",
        "\n",
        "    if n_samples%200 == 0:\n",
        "        print(f\"{n_samples} sentences processed\")\n",
        "        acc = (n_correct/n_total)*100\n",
        "        print(f\"Accuracy: {acc:.4f}\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "0yKCvj0mcu_1"
      },
      "outputs": [],
      "source": [
        "pred_sense_set = set(pred)\n",
        "true_sense_set = set(true)\n",
        "all_senses = sorted(list(true_sense_set.union(pred_sense_set)))\n",
        "not_predicted = true_sense_set - pred_sense_set\n",
        "extra_predicted = pred_sense_set - true_sense_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS2imPibGSEe",
        "outputId": "a1fe36e2-3cdd-4960-da10-a3edf3a271c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/krishna/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/krishna/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.3478\n",
            "Precision: 0.3837\n",
            "Recall: 0.3739\n",
            "F1-Score: 0.3488\n"
          ]
        }
      ],
      "source": [
        "acc = accuracy_score(true, pred)\n",
        "prec = precision_score(true, pred, average = \"macro\")\n",
        "rec = recall_score(true, pred, average = \"macro\")\n",
        "f1 = f1_score(true, pred, average = \"macro\")\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Bsb2D-5bfxE7"
      },
      "outputs": [],
      "source": [
        "def predict(sent):\n",
        "\n",
        "    senses = []\n",
        "    tokens = word_tokenize(sent)\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "    tags = [treebank2wn(p[1]) for p in tagged]\n",
        "    tokens = [lemmatize(w, tag) for w, tag in zip(tokens, tags)]\n",
        "    n_tokens = len(tokens)\n",
        "\n",
        "    for i in range(n_tokens):\n",
        "\n",
        "        w = tokens[i]\n",
        "        tag = tags[i]\n",
        "\n",
        "        context = tokens.copy()\n",
        "        del context[i]\n",
        "\n",
        "        cv = sent2vec(context)\n",
        "\n",
        "        if cv is None:\n",
        "            print(f\"Empty context vector. Word: {w}, Tokens: {tokens}. Using a random vector as context.\")\n",
        "            cv = np.random.rand(300,)\n",
        "\n",
        "        sense_vectors, sense_labels = getCandidates(w, tag)\n",
        "        n_candidates = len(sense_labels)\n",
        "\n",
        "        s_pred = None\n",
        "        if n_candidates == 0:\n",
        "            sense_vectors, sense_labels = getCandidates(w, None)\n",
        "            n_candidates = len(sense_labels)\n",
        "            if n_candidates == 0:\n",
        "                # print(f\"No synsets found: {w}\")\n",
        "                s_pred = None\n",
        "\n",
        "        best = -1 \n",
        "        for j in range(n_candidates):\n",
        "            sv = sense_vectors[j]\n",
        "            cs = cosineSimilarity(cv, sv)\n",
        "            if cs > best:\n",
        "                best = cs\n",
        "                s_pred = sense_labels[j]\n",
        "\n",
        "        senses.append(s_pred)\n",
        "\n",
        "    return senses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez6y5gsegqYt",
        "outputId": "bc1e4616-7270-4d8d-ca76-b0e4ebc3680b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boy.n.02 : a friendly informal reference to a grown man\n",
            "crossed.a.02 : (of a check) marked for deposit only as indicated by having two lines drawn across it\n",
            "river.n.01 : a large natural stream of water (larger than a creek)\n",
            "bank.n.01 : sloping land (especially the slope beside a body of water)\n",
            "rifle.v.02 : go through in search of something; search through someone's belongings in an unauthorized way\n",
            "bank.n.01 : sloping land (especially the slope beside a body of water)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sents = [\n",
        "    \"The boy crossed the river bank to go to the bank\", \n",
        " ]\n",
        "\n",
        "for sent in sents:\n",
        "    senses = predict(sent)\n",
        "    for s in senses:\n",
        "        if s is not None:\n",
        "            print(s, \":\", wn.synset(s).definition())\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CS626-A2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
